{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "args = {\n",
    "    \n",
    "    \"image\":r\"C:\\Users\\Priyanka Sawant\\Desktop\\Python\\credit card ocr\\img\\credit_card_01.png\",\n",
    "     \"image2\":r\"C:\\Users\\Priyanka Sawant\\Desktop\\Python\\credit card ocr\\img\\credit_card_03.png\",\n",
    "    \n",
    "     \"image3\":r\"C:\\Users\\Priyanka Sawant\\Desktop\\Python\\credit card ocr\\img\\Credit-Card_00B.jpg\",\n",
    "    \"reference\":r\"C:\\Users\\Priyanka Sawant\\Desktop\\Python\\credit card ocr\\reference\\ocr_a_reference.png\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary that maps the first digit of a credit card\n",
    "# number to the credit card type\n",
    "FIRST_NUMBER = {\n",
    "    \"3\": \"American Express\",\n",
    "    \"4\": \"Visa\",\n",
    "    \"5\": \"MasterCard\",\n",
    "    \"6\": \"Discover Card\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference OCR-A image from disk, convert it to grayscale,\n",
    "# and threshold it, such that the digits appear as *white* on a\n",
    "# *black* background\n",
    "# and invert it, such that the digits appear as *white* on a *black*\n",
    "ref = cv2.imread(args[\"reference\"])\n",
    "ref = cv2.cvtColor(ref, cv2.COLOR_BGR2GRAY)\n",
    "ref = cv2.threshold(ref, 10, 255, cv2.THRESH_BINARY_INV)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the OCR-A image (i.e,. the outlines of the digits)\n",
    "# sort them from left to right, and initialize a dictionary to map\n",
    "# digit name to the ROI\n",
    "refCnts = cv2.findContours(ref.copy(), cv2.RETR_EXTERNAL,\n",
    "    cv2.CHAIN_APPROX_SIMPLE)\n",
    "refCnts = imutils.grab_contours(refCnts)\n",
    "refCnts = contours.sort_contours(refCnts, method=\"left-to-right\")[0]\n",
    "digits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the OCR-A reference contours\n",
    "for (i, c) in enumerate(refCnts):\n",
    "\t# compute the bounding box for the digit, extract it, and resize\n",
    "\t# it to a fixed size\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\troi = ref[y:y + h, x:x + w]\n",
    "\troi = cv2.resize(roi, (57, 88))\n",
    "\t# update the digits dictionary, mapping the digit name to the ROI\n",
    "\tdigits[i] = roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a rectangular (wider than it is tall) and square\n",
    "# structuring kernel\n",
    "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3))\n",
    "sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread(args[\"image\"])\n",
    "image = imutils.resize(image, width=300)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# apply a tophat (whitehat) morphological operator to find light\n",
    "# regions against a dark background (i.e., the credit card numbers)\n",
    "tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rectKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Scharr gradient of the tophat image, then scale\n",
    "# the rest back into the range [0, 255]\n",
    "gradX = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=1, dy=0,\n",
    "\tksize=-1)\n",
    "gradX = np.absolute(gradX)\n",
    "(minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "gradX = (255 * ((gradX - minVal) / (maxVal - minVal)))\n",
    "gradX = gradX.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a closing operation using the rectangular kernel to help\n",
    "# cloes gaps in between credit card number digits, then apply\n",
    "# Otsu's thresholding method to binarize the image\n",
    "gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
    "thresh = cv2.threshold(gradX, 0, 255,\n",
    "\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "# apply a second closing operation to the binary image, again\n",
    "# to help close gaps between credit card number regions\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the thresholded image, then initialize the\n",
    "# list of digit locations\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "locs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "for (i, c) in enumerate(cnts):\n",
    "\t# compute the bounding box of the contour, then use the\n",
    "\t# bounding box coordinates to derive the aspect ratio\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\tar = w / float(h)\n",
    "\t# since credit cards used a fixed size fonts with 4 groups\n",
    "\t# of 4 digits, we can prune potential contours based on the\n",
    "\t# aspect ratio\n",
    "\tif ar > 2.5 and ar < 4.0:\n",
    "\t\t# contours can further be pruned on minimum/maximum width\n",
    "\t\t# and height\n",
    "\t\tif (w > 40 and w < 55) and (h > 10 and h < 20):\n",
    "\t\t\t# append the bounding box region of the digits group\n",
    "\t\t\t# to our locations list\n",
    "\t\t\tlocs.append((x, y, w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the digit locations from left-to-right, then initialize the\n",
    "# list of classified digits\n",
    "locs = sorted(locs, key=lambda x:x[0])\n",
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the 4 groupings of 4 digits\n",
    "for (i, (gX, gY, gW, gH)) in enumerate(locs):\n",
    "\t# initialize the list of group digits\n",
    "\tgroupOutput = []\n",
    "\t# extract the group ROI of 4 digits from the grayscale image,\n",
    "\t# then apply thresholding to segment the digits from the\n",
    "\t# background of the credit card\n",
    "\tgroup = gray[gY - 5:gY + gH + 5, gX - 5:gX + gW + 5]\n",
    "\tgroup = cv2.threshold(group, 0, 255,\n",
    "\t\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\t# detect the contours of each individual digit in the group,\n",
    "\t# then sort the digit contours from left to right\n",
    "\tdigitCnts = cv2.findContours(group.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\tdigitCnts = imutils.grab_contours(digitCnts)\n",
    "\tdigitCnts = contours.sort_contours(digitCnts,\n",
    "\t\tmethod=\"left-to-right\")[0]\n",
    "    # loop over the digit contours\n",
    "\tfor c in digitCnts:\n",
    "\t\t# compute the bounding box of the individual digit, extract\n",
    "\t\t# the digit, and resize it to have the same fixed size as\n",
    "\t\t# the reference OCR-A images\n",
    "\t\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\t\troi = group[y:y + h, x:x + w]\n",
    "\t\troi = cv2.resize(roi, (57, 88))\n",
    "\t\t# initialize a list of template matching scores\t\n",
    "\t\tscores = []\n",
    "\t\t# loop over the reference digit name and digit ROI\n",
    "\t\tfor (digit, digitROI) in digits.items():\n",
    "\t\t\t# apply correlation-based template matching, take the\n",
    "\t\t\t# score, and update the scores list\n",
    "\t\t\tresult = cv2.matchTemplate(roi, digitROI,\n",
    "\t\t\t\tcv2.TM_CCOEFF)\n",
    "\t\t\t(_, score, _, _) = cv2.minMaxLoc(result)\n",
    "\t\t\tscores.append(score)\n",
    "\t\t# the classification for the digit ROI will be the reference\n",
    "\t\t# digit name with the *largest* template matching score\n",
    "\t\tgroupOutput.append(str(np.argmax(scores)))\n",
    "        # draw the digit classifications around the group\n",
    "\tcv2.rectangle(image, (gX - 5, gY - 5),\n",
    "\t\t(gX + gW + 5, gY + gH + 5), (0, 0, 255), 2)\n",
    "\tcv2.putText(image, \"\".join(groupOutput), (gX, gY - 15),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2)\n",
    "\t# update the output digits list\n",
    "\toutput.extend(groupOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card Type: Visa\n",
      "Credit Card #: 4000123456789010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test1- display the output credit card information to the screen\n",
    "print(\"Credit Card Type: {}\".format(FIRST_NUMBER[output[0]]))\n",
    "print(\"Credit Card #: {}\".format(\"\".join(output)))\n",
    "cv2.imshow(\"Image\", image)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
